% !TeX spellcheck = en_GB

\npsection{Introduction}

Ten years have just passed\footnote{At the moment of writing, in October 2022.} since what is informally considered the beginning of the \textit{Deep Learning Revolution} -- the landslide series of records in \textit{visual recognition} competitions shattered by \texttt{AlexNet}\footnote{See \cite{KrizhevskyEtAl2012AlexNet}.}, a \textit{deep artificial neural network} whose training had been accelerated by the use of \textit{graphical processing units}. It surely was not the first of its kind -- and indeed the origin of the field may be traced back to the seminal and overenthusiastic work of McCulloch \& Pitts\footnote{See \cite{McCullochPitts1990ALC}.}, the critical but fundamental contributions from Minsky \& Papert\footnote{See \cite{MinskyPapert1969Perceptrons}.}, or the more recent and optimistic introduction of the \textit{error backpropagation} algorithm\footnote{See \cite{RumelhartEtAl1986LearningRB}.} which is now the almost-unanimous choice for the training of \textit{deep neural architectures}... and all the crucial developments in between\footnote{text} -- but the successes of \texttt{AlexNet} showed, probably for the first time outside the strictly academic community, the actual effectiveness of the convergence of \textit{abundance of data}, \textit{abundance of computing power} and properly trained \textit{deep neural networks}. It was also the time \textit{big data} were becoming popular in industry\footnote{See, \textit{e.g.}, \href{https://trends.google.com/trends/explore?date=all\&q=big\%20data,Deep\%20learning}{the rise in related Google searches}.}, and this contributed to further propel the field of \textit{machine learning} (of which \textit{deep learning} is part, and at the forefront) ahead.

\textit{Fast-forward} to today, and \textit{deep learning} has been endowed with not only an almost-ubiquitous role in everyday life of industrial societies (think, non-exhaustively, \textit{e.g.}, of voice recognition in \textit{smart devices}, recommender systems part of online multimedia-streaming or shopping platforms, realtime automated text-translation services), but also -- and most importantly -- with growing stakes in the decision process at many levels. In a varied landscape across countries -- legally and socially --, it is currently not unusual to have \textit{deep} (or, more generally, \textit{machine}) \textit{learning} systems assist or even replace the driver of a motor vehicle, perform candidate screening in human resource management, assess the solvability of potential debtors, validate insurance claims, aid medical diagnosis, plan and control supply-chain and manufacturing pipelines, \textit{etc.}, among the many scenarios.

The clear explanation of such a widespread and ever growing use of \textit{deep learning} lies in its sheer effectiveness -- provided enough data and \textit{compute} are available -- in producing \textit{data-adaptive} models without requiring reliance on handcrafted features, and in the ever more capable\footnote{See \href{https://paperswithcode.com/sota}{the SotA section of the {PapersWithCode} project} for a non-exhaustive overview of their capabilities.} systems devised thanks to increased understanding, research interest, and funding of such active and promising field.

Nonetheless, on the one hand, with the fast development of the area also comes an increased awareness and interest towards its limitations, their far-reaching implications, and potential ways to address such shortcomings; on the other hand, greater and growing adoption increases scrutiny, and interest in the transformations such new technology is producing upon society -- for the good or bad -- especially in those cases where \textit{things do not go as planned}: anomalies, tampering, misuse, or simply an outcome perceived as unsatisfactory or damaging by some specific social group or subject.

The same interest -- the latter in particular -- is shared and closely followed by \textit{law-} and \textit{policy- makers}, in the attempt to find a delicate balance between the interests of all parties involved: the \textit{research and development} community, the providers of services based on \textit{deep learning}, its final users -- usually at the corporate level, and all those (natural persons or otherwise) whose data are ingested by such systems and who may be finally affected by their output.

In such regard, the \textit{Joint Research Committee of the European Commission} -- while acknowledging that the goal of a cohesive regulatory framework is distant, but urgently needed -- offers\footnote{See \cite{HamonEtAl2020Europe}.} two crucial directions for both the technical and legal community to follow, in order to ease normation and promote the development of \textit{artificial intelligence} in the spirit of the already in-place GDPR\footnote{General Data Protection Regulation of the European Union, \textit{i.e.} \texttt{EU Regulation 2016/679}.}: \textit{explainability} and \textit{robustness} for such systems.

Along the lines of the latter of the two this work will develop. Specifically, the problem of \textit{adversarial} robustness in \textit{image classification} tasks by means of \textit{deep artificial neural networks} will be addressed, and a novel technique to foil \textit{gradient-based adversarial attacks} directed to the inputs of such architectures will be proposed and assessed.

Furthermore, from a purely scientific and more speculative viewpoint, the problem of (the lack of) \textit{(adversarial) robustness} in otherwise extraordinarily capable, modern \textit{deep learning} architectures may help to shed some light -- though maybe just a glimpse -- on the nature of biological intelligence and cognitive processes, and on how artificial \textit{machine learning} systems may improve in key aspects by mimicking them. As such, this work places itself also at the intersection of the study of \textit{artificial} and \textit{biological} intelligence. Fields with common roots (\textit{e.g.}, \cite{McCullochPitts1990ALC} is significant), whose goals, methods, and communities have since partially diverged, but whose deep similarities under the appropriate lens still persist, whose at times surprising differences force us to reason about their very nature and specificity, and whose potential for cross-fertilization never ceases to attract the endless stream of human endeavour.